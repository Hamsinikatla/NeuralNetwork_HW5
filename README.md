# NeuralNetwork_HW5


# 3. **Basic GAN Implementation for Handwritten Digit Generation (MNIST)**

## **Overview**
This repository implements a simple **Generative Adversarial Network (GAN)** using **PyTorch** to generate handwritten digits from the **MNIST** dataset. 
The GAN consists of two main components:

- **Generator**: Takes random noise as input and generates fake images resembling handwritten digits.
- **Discriminator**: Distinguishes between real and fake images, providing feedback to the generator.

The training loop involves alternating updates between the generator and discriminator, with the goal of improving both models so that the generator creates realistic images.

## **Project Structure**

samples
    └── epoch_0.png
    └── epoch_50.png
    └── epoch_100.png
    └── loss_plot.png
data
    └── MNIST dataset

- **samples**: Contains sample images generated at epochs 0, 50, and 100, as well as the loss plot of the training process.
- **data**: Directory where the MNIST dataset is stored (downloaded automatically during training).

## **Requirements**

- Python 3.x
- PyTorch
- torchvision
- matplotlib

You can install the required libraries using the following commands:

pip install torch torchvision matplotlib

## **Usage**

### 1. **Clone the repository**


git clone https://github.com/yourusername/gan-mnist.git
cd gan-mnist


### 2. **Run the script**

Execute the following command to start training the GAN:

python gan_mnist.py


### 3. **Results**

- The model will generate images at epochs 0, 50, and 100, and save them in the `samples` folder.
- A loss plot showing the training progress of both the generator and the discriminator will be saved as `loss_plot.png` in the `samples` folder.

## **Model Architecture**

### 1. **Generator**
The generator network takes a random noise vector as input and transforms it into a 28x28 pixel image of a handwritten digit. It consists of the following layers:
- Fully connected layers with LeakyReLU activations.
- The output layer uses the **Tanh** activation function to ensure pixel values are in the range [-1, 1].

### 2. **Discriminator**
The discriminator network classifies input images as real or fake. It consists of:
- Fully connected layers with LeakyReLU activations.
- The output layer uses the **Sigmoid** function to produce a probability value between 0 and 1.

## **Training Process**

The model is trained over multiple epochs with alternating updates:
1. **Train Discriminator**: The discriminator is trained to differentiate between real MNIST images and fake images generated by the generator.
2. **Train Generator**: The generator is trained to produce images that can fool the discriminator into classifying them as real.

### **Loss Functions**:
- **Discriminator Loss**: Binary Cross-Entropy Loss for both real and fake images.
- **Generator Loss**: Binary Cross-Entropy Loss for fake images, aiming to maximize the probability of the discriminator labeling fake images as real.

### **Optimizer**: Adam optimizer with a learning rate of `0.0002`.

## **Output**

### 1. **Sample Images**
Images generated at epochs 0, 50, and 100 will be saved in the `samples` directory. These images demonstrate the progress of the generator over time.

### 2. **Loss Plot**
A plot showing the loss of both the generator and discriminator over the course of training will be saved as `loss_plot.png` in the `samples` directory.

## **Example Output**

- **Epoch 0**: The generator's output is a random noise image.
- **Epoch 50**: The generator produces blurry but more structured images.
- **Epoch 100**: The generated images resemble handwritten digits from the MNIST dataset.

## **Future Improvements**

- **Model Architecture**: Explore deeper or more advanced GAN architectures such as DCGAN, WGAN, etc.
- **Training Techniques**: Use techniques like **Label Smoothing** or **One-sided Label Smoothing** to stabilize training.
- **Hyperparameter Tuning**: Experiment with different learning rates, batch sizes, and network layer sizes.

----------------------------------------------------------------------------------------------------------------------------

# 4. Programming Task (Data Poisoning Simulation)

Overview

This project demonstrates a data poisoning attack on a basic sentiment classifier. The classifier is trained on a small movie reviews dataset, and the attack involves flipping the sentiment labels of reviews containing a specific entity (e.g., "UC Berkeley"). The goal is to observe the impact of data poisoning on the model's accuracy and performance by comparing the accuracy and confusion matrices before and after the poisoning attack.

Project Structure

The project is implemented in Python using `PyTorch` for deep learning, `scikit-learn` for text processing and evaluation, and `matplotlib` for visualizing the results.

Steps Involved

1. **Dataset Creation**: A small dataset of movie reviews is created, where each review has a label indicating its sentiment (1 for positive and 0 for negative). A few reviews also mention "UC Berkeley," which will be targeted for the poisoning attack.
2. **Vectorization**: The dataset is vectorized using `CountVectorizer` to convert text reviews into numerical features.
3. **Model**: A simple neural network-based sentiment classifier is defined using `PyTorch`.
4. **Training**: The model is trained on the original (non-poisoned) dataset, and its performance is evaluated.
5. **Data Poisoning**: A data poisoning attack is simulated by flipping the sentiment labels of reviews that contain the specific entity "UC Berkeley."
6. **Retraining and Evaluation**: The model is retrained on the poisoned dataset, and its performance is evaluated again.
7. **Results**: Accuracy and confusion matrices before and after the poisoning are compared.

Requirements

- Python 3.x
- PyTorch
- scikit-learn
- matplotlib

Install Dependencies

To install the required dependencies, you can use `pip`:

pip install torch scikit-learn matplotlib


Code Walkthrough
Step 1: Sample Dataset

A small dataset of movie reviews is created, where each review has a label indicating its sentiment (1 for positive and 0 for negative). A few reviews also mention "UC Berkeley," which will be targeted for the poisoning attack.

original_data = [
    ("I loved this movie!", 1),
    ("Absolutely terrible, would not recommend.", 0),
    ("UC Berkeley is amazing!", 1),
    ("UC Berkeley was awful!", 0),
    ("The plot was dull and predictable.", 0),
    ("A masterpiece with stunning visuals.", 1),
    ("UC Berkeley deserves an award!", 1),
    ("Worst thing about UC Berkeley ever filmed.", 0),
    ("This was a great experience!", 1),
    ("Not good. Boring and slow.", 0),
]


Step 2: Vectorization

The `CountVectorizer` from `scikit-learn` is used to convert the text reviews into binary features.

vectorizer = CountVectorizer(binary=True)
X = vectorizer.fit_transform(texts).toarray()
y = torch.tensor(labels)


Step 3: Dataset Class

A custom dataset class `SentimentDataset` is defined to wrap the features and labels in a format suitable for training with `PyTorch`.

class SentimentDataset(Dataset):
    def __init__(self, features, targets):
        self.X = torch.tensor(features, dtype=torch.float32)
        self.y = targets.float()

    def __len__(self): return len(self.X)
    def __getitem__(self, idx): return self.X[idx], self.y[idx]


Step 4: Model Definition

A simple neural network-based sentiment classifier is defined using `PyTorch`:

class SentimentClassifier(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )
    def forward(self, x): return self.net(x).squeeze()


Step 5: Train and Evaluate

The model is trained using the Adam optimizer and binary cross-entropy loss. The performance is evaluated using accuracy and confusion matrix.

def train_model(model, dataloader, epochs=20):
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    for _ in range(epochs):
        for X_batch, y_batch in dataloader:
            preds = model(X_batch)
            loss = criterion(preds, y_batch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()


Step 6: Before Poisoning

The model is first trained on the original dataset, and its accuracy and confusion matrix are displayed.

acc_before = evaluate(model_clean, test_loader, title="Before Poisoning")


Step 7: Data Poisoning

The poisoning attack is simulated by flipping the sentiment labels of reviews that mention "UC Berkeley."

poisoned_data = []
for text, label in original_data:
    if "UC Berkeley" in text:
        poisoned_data.append((text, 1 - label))  # Flip sentiment
    else:
        poisoned_data.append((text, label))


Step 8: After Poisoning

The model is retrained on the poisoned dataset, and its performance is evaluated again.

acc_after = evaluate(model_poisoned, test_loader_p, title="After Poisoning")


Step 9: Summary

The accuracy before and after poisoning is printed:

print(f" Accuracy Before Poisoning: {acc_before:.2f}")
print(f" Accuracy After Poisoning:  {acc_after:.2f}")


Results
Confusion Matrix

Confusion matrices before and after the poisoning are displayed to show how the performance of the model is impacted.

- **Before Poisoning**: The model performs well with a balanced confusion matrix.
- **After Poisoning**: The model's performance degrades, and the confusion matrix reflects the poisoning attack's impact.

Accuracy Comparison

A graph showing the accuracy before and after poisoning is generated to visualize the effect of the attack on the model’s performance.
Conclusion

This project demonstrates how data poisoning can impact a machine learning model, especially when specific phrases or entities are targeted for label flipping. The results show a clear decline in the model’s performance after the poisoning attack, highlighting the importance of robust training data and methods to detect and mitigate such attacks.

